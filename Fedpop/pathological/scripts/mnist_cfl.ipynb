{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper import ExperimentLogger, display_train_stats\n",
    "from fl_devices import Server, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and concate dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "train_dataset = MNIST('raw_data', download=True, train=True)\n",
    "test_dataset = MNIST('raw_data', download=True, train=False)\n",
    "\n",
    "data =  torch.cat([\n",
    "    torch.tensor(train_dataset.data),\n",
    "    torch.tensor(test_dataset.data)\n",
    "])\n",
    "\n",
    "targets = torch.cat([\n",
    "    torch.tensor(train_dataset.targets),\n",
    "    torch.tensor(test_dataset.targets)\n",
    "])\n",
    "\n",
    "class SubMNIST(Dataset):\n",
    "\n",
    "    def __init__(self, indices, data, targets) -> None:\n",
    "\n",
    "        self.indices = indices\n",
    "        self.transform = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "        self.data = data[self.indices]\n",
    "        self.targets = targets[self.indices]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build client datasets\n",
    "N_CLIENTS = 100\n",
    "import pickle\n",
    "\n",
    "\n",
    "client_train_dataset = []\n",
    "test_indices = []\n",
    "base_path = '../data/mnist/all_data/train'\n",
    "for task_id, task_dir in enumerate(os.listdir(base_path)):\n",
    "    data_path = os.path.join(base_path, task_dir, 'train.pkl')\n",
    "    with open(data_path, 'rb') as f:\n",
    "        indices = pickle.load(f)\n",
    "    client_dataset = SubMNIST(indices, data, targets)\n",
    "    client_train_dataset.append(client_dataset)\n",
    "\n",
    "    data_path = os.path.join(base_path, task_dir, 'test.pkl')\n",
    "    with open(data_path, 'rb') as f:\n",
    "        indices = pickle.load(f)\n",
    "    test_indices.extend(indices)\n",
    "test_dataset = SubMNIST(test_indices, data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MnistPerceptron(nn.Module):\n",
    "    def __init__(self, num_classes) -> None:\n",
    "        super(MnistPerceptron, self).__init__()\n",
    "        self.fc = nn.Linear(28*28, 128)\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc(x))\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [Client(MnistPerceptron, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9, weight_decay=5e-4), dat, idnum=i) \n",
    "           for i, dat in enumerate(client_train_dataset)]\n",
    "server = Server(MnistPerceptron, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMUNICATION_ROUNDS = 200\n",
    "EPS_1 = 0.03  # 0.05 in seed 42\n",
    "EPS_2 = 0.5 # 0.5 in seed 42, 0.7 in seed 43\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    \n",
    "cfl_stats = ExperimentLogger()\n",
    "    \n",
    "cluster_indices = [np.arange(len(clients)).astype(\"int\")]\n",
    "client_clusters = [[clients[i] for i in idcs] for idcs in cluster_indices]\n",
    "\n",
    "\n",
    "for c_round in range(1, COMMUNICATION_ROUNDS+1):\n",
    "\n",
    "    if c_round == 1:\n",
    "        for client in clients:\n",
    "            client.synchronize_with_server(server)\n",
    "            \n",
    "    participating_clients = server.select_clients(clients, frac=1.0)\n",
    "\n",
    "    for client in participating_clients:\n",
    "        train_stats = client.compute_weight_update(epochs=1)\n",
    "        client.reset()\n",
    "\n",
    "    similarities = server.compute_pairwise_similarities(clients)\n",
    "\n",
    "    cluster_indices_new = []\n",
    "    for idc in cluster_indices:\n",
    "        max_norm = server.compute_max_update_norm([clients[i] for i in idc])\n",
    "        mean_norm = server.compute_mean_update_norm([clients[i] for i in idc])\n",
    "             \n",
    "        if mean_norm<EPS_1 and max_norm>EPS_2 and len(idc)>2 and c_round>20:\n",
    "            \n",
    "            server.cache_model(idc, clients[idc[0]].W, acc_clients)\n",
    "            \n",
    "            c1, c2 = server.cluster_clients(similarities[idc][:,idc]) \n",
    "            cluster_indices_new += [c1, c2]\n",
    "             \n",
    "            cfl_stats.log({\"split\" : c_round})\n",
    "\n",
    "        else:\n",
    "            cluster_indices_new += [idc]\n",
    "        \n",
    "        \n",
    "    cluster_indices = cluster_indices_new\n",
    "    client_clusters = [[clients[i] for i in idcs] for idcs in cluster_indices]\n",
    "\n",
    "    server.aggregate_clusterwise(client_clusters)\n",
    "\n",
    "    acc_clients = [client.evaluate() for client in clients]\n",
    "    \n",
    "    cfl_stats.log({\"acc_clients\" : acc_clients, \"mean_norm\" : mean_norm, \"max_norm\" : max_norm,\n",
    "                  \"rounds\" : c_round, \"clusters\" : cluster_indices})\n",
    "    logging.info(f\"the mean accuracy is {np.mean(acc_clients, axis=0)} at rount {c_round}\")\n",
    "    \n",
    "    \n",
    "    display_train_stats(cfl_stats, EPS_1, EPS_2, COMMUNICATION_ROUNDS)\n",
    "\n",
    "    \n",
    "for idc in cluster_indices:    \n",
    "    server.cache_model(idc, clients[idc[0]].W, acc_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "path = \"../plot/cfl_result/mnist\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(path, f\"seed_{SEED}.pkl\"), 'wb') as f:\n",
    "    pickle.dump(cfl_stats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
