{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, optimizers, metrics\n",
    "from  tqdm import *\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局参数\n",
    "NUM_USER = 100\n",
    "np.random.seed(12)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可调参数\n",
    "loss_fn = losses.SparseCategoricalCrossentropy()\n",
    "metrics_list = [tf.keras.metrics.Accuracy()]\n",
    "# optimizer = optimizers.SGD(learning_rate=1e-2)\n",
    "optimizer_class = optimizers.SGD\n",
    "E = 3\n",
    "batch_size = 20\n",
    "hidden_unit = 100\n",
    "# beta = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 加载数据\n",
    "with open('../data/mnist/train_array.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('../data/mnist/test_array.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "# 计算相似矩阵\n",
    "W = np.zeros((NUM_USER, NUM_USER))\n",
    "select_digit = list(map(np.unique, [test_data['user_data'][i]['y'] for i in range(NUM_USER)]))\n",
    "W = [len(np.intersect1d(select_digit[i], select_digit[j]))/4. for i in range(NUM_USER) for j in range(NUM_USER)]\n",
    "W = np.array(W).reshape(NUM_USER, -1)\n",
    "D = np.diag(np.sum(W, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(x):\n",
    "    return x / np.sum(x)\n",
    "\n",
    "class Mnist_PL(tf.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Mnist_PL, self).__init__()\n",
    "        self.fc_1 = layers.Dense(hidden_dim, activation='relu')\n",
    "        self.fc_20 = layers.Dense(10)\n",
    "        self.fc_21 = layers.Dense(10)\n",
    "        self.c = tf.Variable(normalization(tf.random.uniform([2, 1], maxval=1, dtype=tf.float32)), trainable=False,\n",
    "                             dtype=tf.float32)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.fc_1(x)\n",
    "        a_20 = self.fc_20(x)\n",
    "        a_21 = self.fc_21(x)\n",
    "        self.z = layers.concatenate([a_20, a_21]).numpy()  # storge for update c\n",
    "        output = layers.Add()([tf.multiply(self.c[0], a_20),\n",
    "                               tf.multiply(self.c[1], a_21),\n",
    "                               ])\n",
    "        output = layers.Softmax()(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 客户端模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client():\n",
    "    def __init__(self, id, hidden_unit, train_data={'x':[], 'y':[]}, \n",
    "                 test_data={'x':[], 'y':[]}, **kwargs):\n",
    "        self.id = id\n",
    "        self.train_data = {'x':np.array(train_data['x']), \n",
    "                           'y':np.array(train_data['y'])}\n",
    "        self.test_data = {'x':np.array(test_data['x']), \n",
    "                           'y':np.array(test_data['y'])}\n",
    "        self.train_samples = len(train_data['y'])\n",
    "        self.test_samples = len(test_data['y'])\n",
    "        self.model = Mnist_PL(hidden_unit)\n",
    "        self.index = np.arange(self.train_samples)\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "        \n",
    "        assert hasattr(self, 'E')\n",
    "        assert hasattr(self, 'optimizer')\n",
    "        assert hasattr(self, 'lr')  # \n",
    "        assert hasattr(self, 'loss_fn')\n",
    "        assert hasattr(self, 'metrics')\n",
    "        self.init_model()\n",
    "        self.optimizer = kwargs['optimizer'](self.lr)\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def init_model(self):\n",
    "        '''\n",
    "        using call method to initialize net parameters.\n",
    "        '''\n",
    "        init_feature = tf.cast(self.test_data['x'][:5], dtype=tf.float32)\n",
    "        _ = self.model(init_feature)\n",
    "    \n",
    "    def forward(self, communication_round=None):\n",
    "        if communication_round<=40:\n",
    "            self.optimizer = self.kwargs['optimizer'](1e-1)\n",
    "        else:\n",
    "            self.optimizer = self.kwargs['optimizer'](5e-2)\n",
    "        np.random.shuffle(self.index)\n",
    "        self.select_index = self.index[:self.batch_size * self.E]\n",
    "\n",
    "        train_set = tf.data.Dataset.from_tensor_slices((self.train_data[\"x\"][self.select_index],\n",
    "                                                        self.train_data[\"y\"][self.select_index])).batch(self.batch_size)\n",
    "        local_round = 0\n",
    "        for feature, label in train_set:\n",
    "            with tf.GradientTape() as tape:\n",
    "                predict = self.model(feature)  # without softmax\n",
    "                loss = self.loss_fn(label, predict)\n",
    "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "            local_round += 1\n",
    "        return (self.model.trainable_variables, self.model.c.numpy())\n",
    "    \n",
    "    def update_variables(self, new_variables):\n",
    "        \"\"\"\n",
    "        :param\n",
    "            new_variables: tuple, each element is ndarray\n",
    "        :result: None, only copy server model\n",
    "        \"\"\"\n",
    "        assert len(self.model.trainable_variables) == len(new_variables)\n",
    "        for i in range(len(new_variables)):\n",
    "            self.model.trainable_variables[i].assign(new_variables[i])\n",
    "\n",
    "\n",
    "    def update_c(self, new_variables, D_row, W_row):\n",
    "        \"\"\"\n",
    "        :param\n",
    "            D_row: 2λ W.dot(C)[i, :]\n",
    "            W_row: 2λ D.dot(C)[i, :]\n",
    "        \"\"\"\n",
    "        self.update_variables(new_variables)\n",
    "        c_old = self.model.c.numpy()  # ndim = 2\n",
    "        c_new = np.zeros_like(c_old)  # ndim = 2\n",
    "        batch_x = self.train_data['x'][self.select_index]\n",
    "        batch_y = self.train_data['y'][self.select_index]\n",
    "        \n",
    "        batchx_tensor = tf.cast(batch_x, dtype=tf.float32)\n",
    "        predict = self.model(batchx_tensor).numpy()\n",
    "        \n",
    "        batchy_tensor = tf.cast(batch_y, tf.int32)\n",
    "        onehot_y = tf.one_hot(batchy_tensor, 10).numpy()  # shape is (N, 10), numpy\n",
    "        # Z = np.transpose(self.model.z.reshape(-1, 10, c_num), [0, 2, 1])\n",
    "        Z = np.transpose(self.model.z.reshape(-1, 10, 2), [0, 2, 1])  # numpy, shape is (N, 10, 10)\n",
    "        predict = np.expand_dims(predict, axis=2)\n",
    "        onehot_y = np.expand_dims(onehot_y, axis=2)\n",
    "        # Z_T = self.model.z.reshape(-1, 10, c_num)\n",
    "        Z_T = self.model.z.reshape(-1, 10, 2)\n",
    "        # one_hot for y\n",
    "        for i in range(self.model.c.shape[0]):\n",
    "            c_new[i] = c_old[i] * ((np.squeeze(tf.reduce_mean(tf.matmul(Z, onehot_y) ,axis=0).numpy()) + W_row)[i] +\n",
    "            tf.reduce_mean(tf.matmul(Z, predict), axis=0).numpy().T.dot(c_old) + D_row.T.dot(c_old.ravel())) / (\n",
    "               (np.squeeze(tf.reduce_mean(tf.matmul(Z, predict), axis=0).numpy()) + D_row)[i] + tf.reduce_mean(tf.matmul(Z, onehot_y), axis=0).numpy().T.dot(c_old) + \n",
    "                W_row.T.dot(c_old.ravel()))\n",
    "        \n",
    "        # c_[i] = self.c[i] * ((X_.T.dot(y) + W_row)[i] + X_.T.dot(X_).dot(self.c).T.dot(self.c) + D_row.T.dot(self.c)) / ((X_.T.dot(X_).dot(self.c)+D_row)[i] + X_.T.dot(y).T.dot(self.c) + W_row.T.dot(self.c))\n",
    "        \n",
    "        c_new[c_new<0] = 1e-6\n",
    "        c_new = normalization(c_new)\n",
    "        assert np.ndim(c_new) == 2\n",
    "        self.model.c.assign(c_new)\n",
    "    \n",
    "    def md_c(self, new_variables, D_row, W_row, lr=1e-1):\n",
    "        self.update_variables(new_variables)\n",
    "        batch_x = self.train_data['x'][self.select_index]\n",
    "        batch_y = self.train_data['y'][self.select_index]\n",
    "        batch_x = tf.cast(batch_x, dtype=tf.float32)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.model.c)\n",
    "            prediction = self.model(batch_x)\n",
    "            loss = loss_fn(batch_y, prediction)\n",
    "        grads_c = tape.gradient(loss, self.model.c)\n",
    "        assert grads_c is not None\n",
    "        grads_c += tf.reshape(tf.cast(D_row-W_row, dtype=tf.float32), self.model.c.shape) \n",
    "        grads_c = self.model.c * tf.exp(-lr * grads_c)  # TODO\n",
    "        self.model.c.assign(grads_c/tf.reduce_sum(grads_c))\n",
    "        \n",
    "    \n",
    "    def test(self):\n",
    "        test_set = tf.data.Dataset.from_tensor_slices((self.test_data[\"x\"], self.test_data[\"y\"])).batch(self.test_samples)\n",
    "        train_set = tf.data.Dataset.from_tensor_slices((self.train_data[\"x\"], self.train_data[\"y\"])).batch(self.train_samples)\n",
    "        for feature, label in test_set:\n",
    "            output = self.model(feature)\n",
    "            loss = self.loss_fn(label, output).numpy()\n",
    "            \n",
    "        prediction = tf.argmax(output, axis=-1).numpy()\n",
    "\n",
    "        metric_result = []\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "            _ = metric.update_state(self.test_data['y'], prediction)\n",
    "            metric_result.append(metric.result().numpy())\n",
    "        \n",
    "        for feature, label in train_set:\n",
    "            output = self.model(feature)\n",
    "            train_loss = self.loss_fn(label, output).numpy()\n",
    "        # group_idx = tf.argmax(self.model.c, axis=1).numpy()[0]\n",
    "        group_idx = tf.argmax(self.model.c, axis=0).numpy()[0]\n",
    "        return (loss, metric_result, train_loss, group_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 服务端模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server():\n",
    "    def __init__(self, hidden_unit, train_data, test_data, E, optimizer, loss_fn, metrics, lamb, \n",
    "                    batch_size, epoches, D, W, \n",
    "                    lr, #\n",
    "                    filename='/home/dihao/code/PFedL/preliminary/Result/mnist_pfedl.txt'):\n",
    "        self.hidden_unit = hidden_unit\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.E = E\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics = metrics\n",
    "        self.lamb = lamb\n",
    "        self.batch_size = batch_size\n",
    "        self.epoches = epoches\n",
    "        self.model = Mnist_PL(hidden_unit)\n",
    "\n",
    "        self.init_model()\n",
    "        self.lastest_model = self.get_parameters()\n",
    "        # self.clients = self.setup_clients()\n",
    "        self.clients = self.setup_clients(lr)\n",
    "        self.C = None\n",
    "        self.file = filename\n",
    "        self.D = D\n",
    "        self.W = W\n",
    "\n",
    "    def init_model(self):\n",
    "        '''\n",
    "        using call method to initialize net parameters.\n",
    "        '''\n",
    "        init_feature = tf.cast(self.test_data[0]['x'][:5], dtype=tf.float32)\n",
    "        _ = self.model(init_feature)\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        parameter = []\n",
    "        for variable in self.model.trainable_variables:\n",
    "            parameter.append(variable.numpy())\n",
    "        return parameter\n",
    "    \n",
    "    def setup_clients(self, lr):\n",
    "        client_list =[]\n",
    "        for i in range(NUM_USER):\n",
    "            client = Client(i, self.hidden_unit, train_data=self.train_data[i], test_data=self.test_data[i],\n",
    "                              E=self.E, optimizer=self.optimizer, loss_fn=self.loss_fn, metrics=self.metrics,\n",
    "                              batch_size=self.batch_size, lr=lr)\n",
    "            client_list.append(client)\n",
    "            \n",
    "        return client_list\n",
    "    \n",
    "    def broadcast(self):\n",
    "        for client in self.clients:\n",
    "            client.update_variables(self.lastest_model)\n",
    "    \n",
    "    def train(self):\n",
    "        dir_name = os.path.dirname(self.file)\n",
    "        self.broadcast()  # broadcast to all clients\n",
    "        for epoch in trange(self.epoches):\n",
    "            client_solution = [client.forward(epoch) for client in self.clients]\n",
    "            # print(\"old_parameter is {}\".format(self.lastest_model[0]))\n",
    "            self.lastest_model, self.C = self.aggragate(client_solution)\n",
    "            # print(\"new_parameter is {}\".format(self.lastest_model[0]))\n",
    "            # self.update_c(self.lastest_model)\n",
    "            self.md_c(self.lastest_model)\n",
    "            \n",
    "            if self.C is not None:\n",
    "                if (epoch+1) % 20 == 0:\n",
    "                    c_path = os.path.join(dir_name, \"c_\"+str(epoch)+\".txt\")\n",
    "                    np.savetxt(c_path, self.C)\n",
    "            round_loss, round_metrics, train_loss, c_acc= self.test()\n",
    "            with open(self.file, 'a+') as f:\n",
    "                f.write('At round {}, test loss is: {:.4f}, metrics result is {}, train loss is {}, c accuracy is {}'.format(epoch, round_loss, round_metrics, train_loss, c_acc))\n",
    "                f.write('\\n')\n",
    "            logging.info('At round {}, test loss is: {:.4f}, metrics result is {}, train loss is {}, c accuracy is {}'.format(epoch, round_loss, round_metrics, train_loss, c_acc))\n",
    "\n",
    "            \n",
    "    def aggragate(self, client_solution):\n",
    "        concate_C = []\n",
    "        concate_V = [np.zeros_like(x) for x in self.lastest_model]\n",
    "        # update lastest_model\n",
    "        for i, solution in enumerate(client_solution):\n",
    "            client_variables, client_c = solution\n",
    "            concate_V = [concate_V[j]+client_variables[j].numpy() for j in range(len(concate_V))]\n",
    "            concate_C.append(client_c)\n",
    "        C = np.concatenate(concate_C).reshape(NUM_USER, 2)\n",
    "        V = [element / NUM_USER*1.0 for element in concate_V]\n",
    "        return (V, C)\n",
    "    \n",
    "    def update_c(self, lastest_model):\n",
    "        for idx, client in enumerate(self.clients):\n",
    "            w_row = self.lamb * self.W.dot(self.C)[idx, :]\n",
    "            d_row = self.lamb * self.D[idx, idx] * self.C[idx, :]\n",
    "            client.update_c(lastest_model, D_row=d_row, W_row=w_row)\n",
    "\n",
    "    def md_c(self, lastest_model):\n",
    "        for idx, client in enumerate(self.clients):\n",
    "            w_row = self.lamb * self.W.dot(self.C)[idx, :]\n",
    "            d_row = self.lamb * self.D[idx, idx] * self.C[idx, :]\n",
    "            client.md_c(lastest_model, D_row=d_row, W_row=w_row)\n",
    "    \n",
    "    def test(self):\n",
    "        loss = []\n",
    "        metrics_list = [[] * len(self.metrics)]\n",
    "        train_loss = []\n",
    "        concate_idx = []\n",
    "        for idx, client in enumerate(self.clients):\n",
    "            client_loss, client_metrics, client_trainloss, group_idx = client.test()\n",
    "            loss.append(client_loss)\n",
    "            train_loss.append(client_trainloss)\n",
    "            concate_idx.append(group_idx)\n",
    "            for i in range(len(metrics_list)):\n",
    "                metrics_list[i].append(client_metrics[i])\n",
    "        \n",
    "        c_acc = tf.equal([0]*50+[1]*50, concate_idx).numpy().sum() / NUM_USER\n",
    "        return np.mean(loss), [np.mean(metrics_list[i]) for i in range(len(metrics_list))], np.mean(train_loss), c_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server = Server(hidden_unit=hidden_unit, train_data=train_data['user_data'], test_data=test_data['user_data'], E=3, optimizer=optimizer_class,\n",
    "loss_fn=loss_fn, metrics=metrics_list, lamb=5e-3, batch_size=20, epoches=200, D=D, W=W, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0:59:39,381 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 118, test loss is: 0.1993, metrics result is [0.9438212], train loss is 0.21253438293933868, c accuracy is 0.0\n",
      " 60%|█████▉    | 119/200 [19:44<14:31, 10.76s/it]2021-02-21 00:59:50,066 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 119, test loss is: 0.1990, metrics result is [0.9445468], train loss is 0.21208690106868744, c accuracy is 0.0\n",
      " 60%|██████    | 120/200 [19:55<14:19, 10.74s/it]2021-02-21 01:00:00,144 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 120, test loss is: 0.1986, metrics result is [0.9441336], train loss is 0.21154659986495972, c accuracy is 0.0\n",
      " 60%|██████    | 121/200 [20:05<13:52, 10.54s/it]2021-02-21 01:00:09,448 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 121, test loss is: 0.1980, metrics result is [0.9438303], train loss is 0.21102474629878998, c accuracy is 0.0\n",
      " 61%|██████    | 122/200 [20:14<13:13, 10.17s/it]2021-02-21 01:00:18,825 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 122, test loss is: 0.1976, metrics result is [0.9433315], train loss is 0.2105700671672821, c accuracy is 0.0\n",
      " 62%|██████▏   | 123/200 [20:23<12:44,  9.93s/it]2021-02-21 01:00:28,782 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 123, test loss is: 0.1969, metrics result is [0.94343275], train loss is 0.21022634208202362, c accuracy is 0.0\n",
      " 62%|██████▏   | 124/200 [20:33<12:35,  9.94s/it]2021-02-21 01:00:38,502 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 124, test loss is: 0.1965, metrics result is [0.9445537], train loss is 0.20960265398025513, c accuracy is 0.0\n",
      " 62%|██████▎   | 125/200 [20:43<12:20,  9.87s/it]2021-02-21 01:00:48,753 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 125, test loss is: 0.1962, metrics result is [0.9447443], train loss is 0.20910699665546417, c accuracy is 0.0\n",
      " 63%|██████▎   | 126/200 [20:53<12:19,  9.99s/it]2021-02-21 01:00:59,012 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 126, test loss is: 0.1960, metrics result is [0.94515884], train loss is 0.208665668964386, c accuracy is 0.0\n",
      " 64%|██████▎   | 127/200 [21:04<12:15, 10.07s/it]2021-02-21 01:01:09,699 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 127, test loss is: 0.1954, metrics result is [0.944742], train loss is 0.20820732414722443, c accuracy is 0.0\n",
      " 64%|██████▍   | 128/200 [21:14<12:18, 10.25s/it]2021-02-21 01:01:18,965 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 128, test loss is: 0.1949, metrics result is [0.94473684], train loss is 0.20776347815990448, c accuracy is 0.0\n",
      " 64%|██████▍   | 129/200 [21:24<11:46,  9.96s/it]2021-02-21 01:01:29,179 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 129, test loss is: 0.1944, metrics result is [0.94435614], train loss is 0.20743028819561005, c accuracy is 0.0\n",
      " 65%|██████▌   | 130/200 [21:34<11:42, 10.03s/it]2021-02-21 01:01:39,172 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 130, test loss is: 0.1940, metrics result is [0.94473666], train loss is 0.20692935585975647, c accuracy is 0.0\n",
      " 66%|██████▌   | 131/200 [21:44<11:31, 10.02s/it]2021-02-21 01:01:49,575 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 131, test loss is: 0.1938, metrics result is [0.94525254], train loss is 0.20650862157344818, c accuracy is 0.0\n",
      " 66%|██████▌   | 132/200 [21:54<11:29, 10.14s/it]2021-02-21 01:01:58,799 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 132, test loss is: 0.1933, metrics result is [0.94536155], train loss is 0.20594093203544617, c accuracy is 0.0\n",
      " 66%|██████▋   | 133/200 [22:03<11:00,  9.86s/it]2021-02-21 01:02:08,499 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 133, test loss is: 0.1930, metrics result is [0.945468], train loss is 0.20550470054149628, c accuracy is 0.0\n",
      " 67%|██████▋   | 134/200 [22:13<10:47,  9.81s/it]2021-02-21 01:02:17,970 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 134, test loss is: 0.1925, metrics result is [0.94555116], train loss is 0.20504631102085114, c accuracy is 0.0\n",
      " 68%|██████▊   | 135/200 [22:23<10:31,  9.71s/it]2021-02-21 01:02:27,893 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 135, test loss is: 0.1921, metrics result is [0.9455572], train loss is 0.20463621616363525, c accuracy is 0.0\n",
      " 68%|██████▊   | 136/200 [22:33<10:25,  9.77s/it]2021-02-21 01:02:38,522 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 136, test loss is: 0.1917, metrics result is [0.9457684], train loss is 0.20421704649925232, c accuracy is 0.0\n",
      " 68%|██████▊   | 137/200 [22:43<10:31, 10.03s/it]2021-02-21 01:02:48,780 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 137, test loss is: 0.1913, metrics result is [0.945567], train loss is 0.20382975041866302, c accuracy is 0.0\n",
      " 69%|██████▉   | 138/200 [22:53<10:26, 10.10s/it]2021-02-21 01:02:58,147 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 138, test loss is: 0.1911, metrics result is [0.94606155], train loss is 0.20341280102729797, c accuracy is 0.0\n",
      " 70%|██████▉   | 139/200 [23:03<10:02,  9.88s/it]2021-02-21 01:03:07,579 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 139, test loss is: 0.1907, metrics result is [0.9453441], train loss is 0.20310933887958527, c accuracy is 0.0\n",
      " 70%|███████   | 140/200 [23:12<09:44,  9.75s/it]2021-02-21 01:03:18,614 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 140, test loss is: 0.1902, metrics result is [0.94564193], train loss is 0.20264120399951935, c accuracy is 0.0\n",
      " 70%|███████   | 141/200 [23:23<09:57, 10.13s/it]2021-02-21 01:03:28,898 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 141, test loss is: 0.1899, metrics result is [0.9461638], train loss is 0.2021491974592209, c accuracy is 0.0\n",
      " 71%|███████   | 142/200 [23:34<09:50, 10.18s/it]2021-02-21 01:03:39,047 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 142, test loss is: 0.1895, metrics result is [0.945854], train loss is 0.2017820179462433, c accuracy is 0.0\n",
      " 72%|███████▏  | 143/200 [23:44<09:39, 10.17s/it]2021-02-21 01:03:48,742 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 143, test loss is: 0.1892, metrics result is [0.94555724], train loss is 0.20139221847057343, c accuracy is 0.0\n",
      " 72%|███████▏  | 144/200 [23:53<09:21, 10.03s/it]2021-02-21 01:03:58,302 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 144, test loss is: 0.1889, metrics result is [0.9461668], train loss is 0.20096389949321747, c accuracy is 0.0\n",
      " 72%|███████▎  | 145/200 [24:03<09:03,  9.89s/it]2021-02-21 01:04:07,786 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 145, test loss is: 0.1884, metrics result is [0.94545084], train loss is 0.20062611997127533, c accuracy is 0.0\n",
      " 73%|███████▎  | 146/200 [24:12<08:47,  9.77s/it]2021-02-21 01:04:18,575 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 146, test loss is: 0.1882, metrics result is [0.945463], train loss is 0.2002440094947815, c accuracy is 0.0\n",
      " 74%|███████▎  | 147/200 [24:23<08:53, 10.07s/it]2021-02-21 01:04:28,523 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 147, test loss is: 0.1881, metrics result is [0.9459698], train loss is 0.1999311000108719, c accuracy is 0.0\n",
      " 74%|███████▍  | 148/200 [24:33<08:41, 10.04s/it]2021-02-21 01:04:37,773 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 148, test loss is: 0.1875, metrics result is [0.94564366], train loss is 0.19954001903533936, c accuracy is 0.0\n",
      " 74%|███████▍  | 149/200 [24:42<08:19,  9.80s/it]2021-02-21 01:04:49,604 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 149, test loss is: 0.1872, metrics result is [0.94626343], train loss is 0.1991015076637268, c accuracy is 0.0\n",
      " 75%|███████▌  | 150/200 [24:54<08:40, 10.41s/it]2021-02-21 01:05:00,886 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 150, test loss is: 0.1868, metrics result is [0.94645804], train loss is 0.19871903955936432, c accuracy is 0.0\n",
      " 76%|███████▌  | 151/200 [25:06<08:42, 10.67s/it]2021-02-21 01:05:10,621 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 151, test loss is: 0.1866, metrics result is [0.9461582], train loss is 0.19840416312217712, c accuracy is 0.0\n",
      " 76%|███████▌  | 152/200 [25:15<08:18, 10.39s/it]2021-02-21 01:05:20,806 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 152, test loss is: 0.1864, metrics result is [0.9462436], train loss is 0.19822214543819427, c accuracy is 0.0\n",
      " 76%|███████▋  | 153/200 [25:25<08:05, 10.33s/it]2021-02-21 01:05:31,608 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 153, test loss is: 0.1860, metrics result is [0.94596255], train loss is 0.19778989255428314, c accuracy is 0.0\n",
      " 77%|███████▋  | 154/200 [25:36<08:01, 10.47s/it]2021-02-21 01:05:41,901 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 154, test loss is: 0.1854, metrics result is [0.94616896], train loss is 0.19729629158973694, c accuracy is 0.0\n",
      " 78%|███████▊  | 155/200 [25:47<07:48, 10.42s/it]2021-02-21 01:05:51,676 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 155, test loss is: 0.1852, metrics result is [0.94626015], train loss is 0.1970495581626892, c accuracy is 0.0\n",
      " 78%|███████▊  | 156/200 [25:56<07:29, 10.22s/it]2021-02-21 01:06:00,869 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 156, test loss is: 0.1847, metrics result is [0.94726706], train loss is 0.19669388234615326, c accuracy is 0.0\n",
      " 78%|███████▊  | 157/200 [26:06<07:06,  9.92s/it]2021-02-21 01:06:10,800 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 157, test loss is: 0.1845, metrics result is [0.9469646], train loss is 0.1962684988975525, c accuracy is 0.0\n",
      " 79%|███████▉  | 158/200 [26:15<06:56,  9.92s/it]2021-02-21 01:06:20,979 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 158, test loss is: 0.1841, metrics result is [0.9463627], train loss is 0.1959427446126938, c accuracy is 0.0\n",
      " 80%|███████▉  | 159/200 [26:26<06:49, 10.00s/it]2021-02-21 01:06:32,015 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 159, test loss is: 0.1839, metrics result is [0.94676864], train loss is 0.19552211463451385, c accuracy is 0.0\n",
      " 80%|████████  | 160/200 [26:37<06:52, 10.31s/it]2021-02-21 01:06:41,526 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 160, test loss is: 0.1837, metrics result is [0.9465604], train loss is 0.19525812566280365, c accuracy is 0.0\n",
      " 80%|████████  | 161/200 [26:46<06:32, 10.07s/it]2021-02-21 01:06:51,896 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 161, test loss is: 0.1831, metrics result is [0.94676363], train loss is 0.19494391977787018, c accuracy is 0.0\n",
      " 81%|████████  | 162/200 [26:57<06:26, 10.16s/it]2021-02-21 01:07:00,867 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 162, test loss is: 0.1828, metrics result is [0.9475631], train loss is 0.19454136490821838, c accuracy is 0.0\n",
      " 82%|████████▏ | 163/200 [27:06<06:02,  9.80s/it]2021-02-21 01:07:12,117 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 163, test loss is: 0.1825, metrics result is [0.9468642], train loss is 0.19422908127307892, c accuracy is 0.0\n",
      " 82%|████████▏ | 164/200 [27:17<06:08, 10.24s/it]2021-02-21 01:07:21,827 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 164, test loss is: 0.1821, metrics result is [0.94706064], train loss is 0.19391612708568573, c accuracy is 0.0\n",
      " 82%|████████▎ | 165/200 [27:26<05:52, 10.08s/it]2021-02-21 01:07:31,327 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 165, test loss is: 0.1821, metrics result is [0.94665664], train loss is 0.1936257928609848, c accuracy is 0.0\n",
      " 83%|████████▎ | 166/200 [27:36<05:36,  9.91s/it]2021-02-21 01:07:42,307 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 166, test loss is: 0.1817, metrics result is [0.9466421], train loss is 0.1932852566242218, c accuracy is 0.0\n",
      " 84%|████████▎ | 167/200 [27:47<05:37, 10.23s/it]2021-02-21 01:07:52,218 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 167, test loss is: 0.1815, metrics result is [0.94756037], train loss is 0.19287307560443878, c accuracy is 0.0\n",
      " 84%|████████▍ | 168/200 [27:57<05:24, 10.13s/it]2021-02-21 01:08:02,803 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 168, test loss is: 0.1810, metrics result is [0.94764274], train loss is 0.192572683095932, c accuracy is 0.0\n",
      " 84%|████████▍ | 169/200 [28:07<05:18, 10.27s/it]2021-02-21 01:08:13,225 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 169, test loss is: 0.1808, metrics result is [0.9477566], train loss is 0.19225458800792694, c accuracy is 0.0\n",
      " 85%|████████▌ | 170/200 [28:18<05:09, 10.31s/it]2021-02-21 01:08:23,731 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 170, test loss is: 0.1807, metrics result is [0.9476566], train loss is 0.19190259277820587, c accuracy is 0.0\n",
      " 86%|████████▌ | 171/200 [28:28<05:00, 10.37s/it]2021-02-21 01:08:33,068 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 171, test loss is: 0.1806, metrics result is [0.94715387], train loss is 0.19172607362270355, c accuracy is 0.0\n",
      " 86%|████████▌ | 172/200 [28:38<04:41, 10.06s/it]2021-02-21 01:08:44,206 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 172, test loss is: 0.1801, metrics result is [0.9473648], train loss is 0.19140473008155823, c accuracy is 0.0\n",
      " 86%|████████▋ | 173/200 [28:49<04:40, 10.38s/it]2021-02-21 01:08:54,425 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 173, test loss is: 0.1796, metrics result is [0.9475547], train loss is 0.19090892374515533, c accuracy is 0.0\n",
      " 87%|████████▋ | 174/200 [28:59<04:28, 10.33s/it]2021-02-21 01:09:04,884 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 174, test loss is: 0.1796, metrics result is [0.9474479], train loss is 0.19061654806137085, c accuracy is 0.0\n",
      " 88%|████████▊ | 175/200 [29:10<04:19, 10.37s/it]2021-02-21 01:09:14,928 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 175, test loss is: 0.1792, metrics result is [0.9482656], train loss is 0.19028545916080475, c accuracy is 0.0\n",
      " 88%|████████▊ | 176/200 [29:20<04:06, 10.27s/it]2021-02-21 01:09:25,208 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 176, test loss is: 0.1790, metrics result is [0.9480577], train loss is 0.1900080144405365, c accuracy is 0.0\n",
      " 88%|████████▊ | 177/200 [29:30<03:56, 10.28s/it]2021-02-21 01:09:34,961 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 177, test loss is: 0.1787, metrics result is [0.9478528], train loss is 0.18971608579158783, c accuracy is 0.0\n",
      " 89%|████████▉ | 178/200 [29:40<03:42, 10.12s/it]2021-02-21 01:09:46,188 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 178, test loss is: 0.1787, metrics result is [0.947743], train loss is 0.18947245180606842, c accuracy is 0.0\n",
      " 90%|████████▉ | 179/200 [29:51<03:39, 10.45s/it]2021-02-21 01:09:55,779 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 179, test loss is: 0.1783, metrics result is [0.9476672], train loss is 0.18916012346744537, c accuracy is 0.0\n",
      " 90%|█████████ | 180/200 [30:00<03:23, 10.19s/it]2021-02-21 01:10:05,788 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 180, test loss is: 0.1782, metrics result is [0.9477492], train loss is 0.18895283341407776, c accuracy is 0.0\n",
      " 90%|█████████ | 181/200 [30:10<03:12, 10.14s/it]2021-02-21 01:10:15,376 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 181, test loss is: 0.1777, metrics result is [0.94773936], train loss is 0.18863578140735626, c accuracy is 0.0\n",
      " 91%|█████████ | 182/200 [30:20<02:59,  9.97s/it]2021-02-21 01:10:25,016 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 182, test loss is: 0.1773, metrics result is [0.9482424], train loss is 0.1882234364748001, c accuracy is 0.0\n",
      " 92%|█████████▏| 183/200 [30:30<02:47,  9.87s/it]2021-02-21 01:10:34,856 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 183, test loss is: 0.1768, metrics result is [0.9479362], train loss is 0.1880018264055252, c accuracy is 0.0\n",
      " 92%|█████████▏| 184/200 [30:40<02:37,  9.86s/it]2021-02-21 01:10:46,376 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 184, test loss is: 0.1767, metrics result is [0.94845957], train loss is 0.18768098950386047, c accuracy is 0.0\n",
      " 92%|█████████▎| 185/200 [30:51<02:35, 10.36s/it]2021-02-21 01:10:56,664 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 185, test loss is: 0.1765, metrics result is [0.9487531], train loss is 0.18743345141410828, c accuracy is 0.0\n",
      " 93%|█████████▎| 186/200 [31:01<02:24, 10.34s/it]2021-02-21 01:11:06,728 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 186, test loss is: 0.1765, metrics result is [0.9480406], train loss is 0.18718589842319489, c accuracy is 0.0\n",
      " 94%|█████████▎| 187/200 [31:11<02:13, 10.26s/it]2021-02-21 01:11:15,975 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 187, test loss is: 0.1760, metrics result is [0.94804513], train loss is 0.18684841692447662, c accuracy is 0.0\n",
      " 94%|█████████▍| 188/200 [31:21<01:59,  9.95s/it]2021-02-21 01:11:27,512 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 188, test loss is: 0.1759, metrics result is [0.9486344], train loss is 0.18653999269008636, c accuracy is 0.0\n",
      " 94%|█████████▍| 189/200 [31:32<01:54, 10.43s/it]2021-02-21 01:11:38,885 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 189, test loss is: 0.1756, metrics result is [0.948334], train loss is 0.1862049698829651, c accuracy is 0.0\n",
      " 95%|█████████▌| 190/200 [31:44<01:47, 10.71s/it]2021-02-21 01:11:49,109 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 190, test loss is: 0.1754, metrics result is [0.9487362], train loss is 0.18593046069145203, c accuracy is 0.0\n",
      " 96%|█████████▌| 191/200 [31:54<01:35, 10.57s/it]2021-02-21 01:11:59,577 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 191, test loss is: 0.1749, metrics result is [0.9488381], train loss is 0.18569143116474152, c accuracy is 0.0\n",
      " 96%|█████████▌| 192/200 [32:04<01:24, 10.54s/it]2021-02-21 01:12:11,102 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 192, test loss is: 0.1747, metrics result is [0.94852453], train loss is 0.18535619974136353, c accuracy is 0.0\n",
      " 96%|█████████▋| 193/200 [32:16<01:15, 10.83s/it]2021-02-21 01:12:21,140 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 193, test loss is: 0.1745, metrics result is [0.94935125], train loss is 0.1850893348455429, c accuracy is 0.0\n",
      " 97%|█████████▋| 194/200 [32:26<01:03, 10.59s/it]2021-02-21 01:12:32,581 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 194, test loss is: 0.1745, metrics result is [0.9484368], train loss is 0.18482451140880585, c accuracy is 0.0\n",
      " 98%|█████████▊| 195/200 [32:37<00:54, 10.85s/it]2021-02-21 01:12:43,149 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 195, test loss is: 0.1740, metrics result is [0.94946694], train loss is 0.18457816541194916, c accuracy is 0.0\n",
      " 98%|█████████▊| 196/200 [32:48<00:43, 10.76s/it]2021-02-21 01:12:55,040 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 196, test loss is: 0.1738, metrics result is [0.9493538], train loss is 0.18429537117481232, c accuracy is 0.0\n",
      " 98%|█████████▊| 197/200 [33:00<00:33, 11.10s/it]2021-02-21 01:13:04,968 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 197, test loss is: 0.1735, metrics result is [0.94924736], train loss is 0.18406853079795837, c accuracy is 0.0\n",
      " 99%|█████████▉| 198/200 [33:10<00:21, 10.75s/it]2021-02-21 01:13:14,666 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 198, test loss is: 0.1734, metrics result is [0.949161], train loss is 0.1837722212076187, c accuracy is 0.0\n",
      "100%|█████████▉| 199/200 [33:19<00:10, 10.43s/it]2021-02-21 01:13:25,010 - <ipython-input-11-cd3180c10b9a>[line:73] - INFO: At round 199, test loss is: 0.1732, metrics result is [0.9492534], train loss is 0.1835155338048935, c accuracy is 0.0\n",
      "100%|██████████| 200/200 [33:30<00:00, 10.05s/it]\n"
     ]
    }
   ],
   "source": [
    "server.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}