{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, optimizers, metrics\n",
    "from  tqdm import *\n",
    "\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局参数\n",
    "NUM_USER = 100\n",
    "np.random.seed(12)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = losses.SparseCategoricalCrossentropy()\n",
    "metrics_list = [tf.keras.metrics.Accuracy()]\n",
    "# optimizer = optimizers.SGD(learning_rate=1e-2)\n",
    "optimizer_class = optimizers.SGD\n",
    "E = 3\n",
    "batch_size = 20\n",
    "hidden_unit = 100\n",
    "beta = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 加载数据\n",
    "with open('../data/mnist/train_array.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('../data/mnist/test_array.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_LG(tf.Module):\n",
    "    def __init__(self, hidden_unit):\n",
    "        \"\"\"\n",
    "        :param\n",
    "            hidden_unit: positive integer, dimensionality of the hidden layer.\n",
    "        \"\"\"\n",
    "        super(Mnist_LG, self).__init__()\n",
    "        self.hidden_unit = hidden_unit\n",
    "        self.fc_1 = layers.Dense(hidden_unit, activation='relu')\n",
    "        self.fc_2 = layers.Dense(10, activation='softmax')\n",
    "        self.global_index = 2\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.fc_1(x)\n",
    "        output = self.fc_2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 客户端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client_LG():\n",
    "    def __init__(self, id, hidden_unit, train_data={'x': [], 'y': []},\n",
    "                 test_data={'x': [], 'y': []}, **kwargs):\n",
    "        self.id = id\n",
    "        self.train_data = {'x': np.array(train_data['x']),\n",
    "                           'y': np.array(train_data['y'])}\n",
    "        self.test_data = {'x': np.array(test_data['x']),\n",
    "                          'y': np.array(test_data['y'])}\n",
    "        self.train_samples = len(train_data['y'])\n",
    "        self.test_samples = len(test_data['y'])\n",
    "        self.index = np.arange(self.train_samples)\n",
    "        self.model = Mnist_LG(hidden_unit)  # TODO:动态的加载类，因为更新方式不一样，所以好像没办法聚合,options应该更好地设置一下\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "        assert hasattr(self, 'E')\n",
    "        assert hasattr(self, 'optimizer')\n",
    "        assert hasattr(self, 'lr')  #\n",
    "        assert hasattr(self, 'loss_fn')\n",
    "        assert hasattr(self, 'metrics')\n",
    "        assert hasattr(self, 'batch_size')\n",
    "        assert (self.batch_size * self.E) < self.train_samples\n",
    "        self.init_model()\n",
    "        self.optimizer = kwargs['optimizer'](self.lr)\n",
    "\n",
    "    def init_model(self):\n",
    "        '''\n",
    "        using call method to initialize net parameters.\n",
    "        :return:\n",
    "        '''\n",
    "        init_feature = tf.cast(self.test_data[\"x\"][:5], dtype=tf.float32)\n",
    "        _ = self.model(init_feature)\n",
    "\n",
    "    def forward(self, communication_round=None):\n",
    "        np.random.shuffle(self.index)\n",
    "        self.select_index = self.index[:self.batch_size * self.E]\n",
    "        train_set = tf.data.Dataset.from_tensor_slices((self.train_data[\"x\"][self.select_index],\n",
    "                                                        self.train_data[\"y\"][self.select_index])).batch(self.batch_size)\n",
    "        local_round = 0\n",
    "        for feature, label in train_set:\n",
    "            with tf.GradientTape() as tape:\n",
    "                predict = self.model(feature)  # without softmax\n",
    "                loss = self.loss_fn(label, predict)\n",
    "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "            local_round += 1\n",
    "        return (self.model.trainable_variables[self.model.global_index:])\n",
    "\n",
    "    def update_variables(self, new_variables):\n",
    "        \"\"\"\n",
    "        :param\n",
    "            new_variables: tuple, each element is ndarray\n",
    "        :result: None, only copy server model\n",
    "        \"\"\"\n",
    "        assert len(self.model.trainable_variables[self.model.global_index:]) == len(new_variables)\n",
    "        for i in range(len(new_variables)):\n",
    "            self.model.trainable_variables[self.model.global_index + i].assign(new_variables[i])\n",
    "\n",
    "    def test(self):\n",
    "        test_set = tf.data.Dataset.from_tensor_slices((self.test_data[\"x\"], self.test_data[\"y\"])).batch(\n",
    "            self.test_samples)\n",
    "        train_set = tf.data.Dataset.from_tensor_slices((self.train_data[\"x\"], self.train_data[\"y\"])).batch(\n",
    "            self.train_samples)\n",
    "        for feature, label in test_set:\n",
    "            output = self.model(feature)\n",
    "            loss = self.loss_fn(label, output).numpy()\n",
    "\n",
    "        prediction = tf.argmax(output, axis=-1).numpy()\n",
    "\n",
    "        metric_result = []\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "            _ = metric.update_state(self.test_data['y'], prediction)\n",
    "            metric_result.append(metric.result().numpy())\n",
    "\n",
    "        for feature, label in train_set:\n",
    "            output = self.model(feature)\n",
    "            train_loss = self.loss_fn(label, output).numpy()\n",
    "        # group_idx = tf.argmax(self.model.c, axis=1).numpy()[0]\n",
    "        # group_idx = tf.argmax(self.model.c, axis=0).numpy()[0]\n",
    "        return (loss, metric_result, train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 服务器端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server_LG():\n",
    "    def __init__(self, hidden_unit, train_data, test_data, E, optimizer, loss_fn, metrics, batch_size, epoches,\n",
    "                 lr, filename='/home/dihao/code/PFedL/preliminary/Result/mnist_lg.txt'):\n",
    "        self.hidden_unit = hidden_unit\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.E = E\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics = metrics\n",
    "        self.batch_size = batch_size\n",
    "        self.epoches = epoches\n",
    "        self.model = Mnist_LG(hidden_unit)\n",
    "\n",
    "        self.init_model()\n",
    "        self.lastest_model = self.get_parameters()\n",
    "        self.clients = self.setup_clients(lr)\n",
    "        self.file = filename\n",
    "\n",
    "    def init_model(self):\n",
    "        '''\n",
    "        using call method to initialize net parameters.\n",
    "        :return:\n",
    "        '''\n",
    "        init_feature = tf.cast(self.test_data[0]['x'][:5], dtype=tf.float32)\n",
    "        _ = self.model(init_feature)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        parameter = []\n",
    "        for variable in self.model.trainable_variables[self.model.global_index:]:\n",
    "            parameter.append(variable.numpy())\n",
    "        return parameter\n",
    "\n",
    "    def setup_clients(self, lr):\n",
    "        client_list = []\n",
    "        for i in range(NUM_USER):\n",
    "            client = Client_LG(i, self.hidden_unit, train_data=self.train_data[i], test_data=self.test_data[i],\n",
    "                            E=self.E, optimizer=self.optimizer, loss_fn=self.loss_fn, metrics=self.metrics,\n",
    "                            batch_size=self.batch_size, lr=lr)\n",
    "            client_list.append(client)\n",
    "\n",
    "        return client_list\n",
    "\n",
    "    def broadcast(self):\n",
    "        for client in self.clients:\n",
    "            client.update_variables(self.lastest_model)\n",
    "\n",
    "    def train(self): \n",
    "        for epoch in trange(self.epoches):\n",
    "            self.broadcast() # broadcast to all clients\n",
    "            client_solution = [client.forward(epoch) for client in self.clients]\n",
    "            self.lastest_model = self.aggragate(client_solution)\n",
    "\n",
    "            round_loss, round_metrics, train_loss = self.test()\n",
    "            with open(self.file, 'a+') as f:\n",
    "                f.write('At round {}, test loss is: {:.4f}, metrics result is {}, train loss is {}'.format(\n",
    "                        epoch, round_loss, round_metrics, train_loss))\n",
    "                f.write('\\n')\n",
    "            logging.info('At round {}, test loss is: {:.4f}, metrics result is {}, train loss is {}'.format(\n",
    "                        epoch, round_loss, round_metrics, train_loss))\n",
    "\n",
    "    def aggragate(self, client_solution):\n",
    "        concate_V = [np.zeros_like(x) for x in self.lastest_model]\n",
    "        # update lastest_model\n",
    "        for i, solution in enumerate(client_solution):\n",
    "            client_variables = solution\n",
    "            concate_V = [concate_V[j] + client_variables[j].numpy() for j in range(len(concate_V))]\n",
    "        V = [element / NUM_USER for element in concate_V]\n",
    "        return V\n",
    "\n",
    "    def test(self):\n",
    "        loss = []\n",
    "        metrics_list = [[] * len(self.metrics)]\n",
    "        train_loss = []\n",
    "        for idx, client in enumerate(self.clients):\n",
    "            client_loss, client_metrics, client_trainloss = client.test()\n",
    "            loss.append(client_loss)\n",
    "            train_loss.append(client_trainloss)\n",
    "            for i in range(len(metrics_list)):\n",
    "                metrics_list[i].append(client_metrics[i])\n",
    "        return np.mean(loss), [np.mean(metrics_list[i]) for i in range(len(metrics_list))], np.mean(train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server_LG(hidden_unit=hidden_unit, train_data=train_data['user_data'], test_data=test_data['user_data'], E=3, optimizer=optimizer_class,\n",
    "loss_fn=loss_fn, metrics=metrics_list, batch_size=20, epoches=200, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2:35<22:37, 15.09s/it]2020-12-17 04:38:51,699 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 10, test loss is: 0.3808, metrics result is [0.92514956], train loss is 0.3415924906730652\n",
      " 11%|█         | 11/100 [02:51<22:27, 15.14s/it]2020-12-17 04:39:05,917 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 11, test loss is: 0.3619, metrics result is [0.92676115], train loss is 0.32113248109817505\n",
      " 12%|█▏        | 12/100 [03:05<21:47, 14.86s/it]2020-12-17 04:39:20,669 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 12, test loss is: 0.3443, metrics result is [0.9302185], train loss is 0.3038184344768524\n",
      " 13%|█▎        | 13/100 [03:20<21:30, 14.83s/it]2020-12-17 04:39:35,428 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 13, test loss is: 0.3310, metrics result is [0.9307283], train loss is 0.2884969413280487\n",
      " 14%|█▍        | 14/100 [03:34<21:13, 14.81s/it]2020-12-17 04:39:50,637 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 14, test loss is: 0.3192, metrics result is [0.93064904], train loss is 0.27508583664894104\n",
      " 15%|█▌        | 15/100 [03:50<21:08, 14.93s/it]2020-12-17 04:40:05,270 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 15, test loss is: 0.3084, metrics result is [0.9314248], train loss is 0.26286938786506653\n",
      " 16%|█▌        | 16/100 [04:04<20:46, 14.84s/it]2020-12-17 04:40:18,991 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 16, test loss is: 0.2976, metrics result is [0.93391526], train loss is 0.25237375497817993\n",
      " 17%|█▋        | 17/100 [04:18<20:03, 14.50s/it]2020-12-17 04:40:33,160 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 17, test loss is: 0.2882, metrics result is [0.93758845], train loss is 0.24238796532154083\n",
      " 18%|█▊        | 18/100 [04:32<19:41, 14.40s/it]2020-12-17 04:40:48,166 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 18, test loss is: 0.2820, metrics result is [0.9350513], train loss is 0.23401057720184326\n",
      " 19%|█▉        | 19/100 [04:47<19:41, 14.58s/it]2020-12-17 04:41:02,008 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 19, test loss is: 0.2746, metrics result is [0.93629557], train loss is 0.22551506757736206\n",
      " 20%|██        | 20/100 [05:01<19:08, 14.36s/it]2020-12-17 04:41:17,205 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 20, test loss is: 0.2691, metrics result is [0.93643975], train loss is 0.2184898406267166\n",
      " 21%|██        | 21/100 [05:16<19:14, 14.61s/it]2020-12-17 04:41:31,804 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 21, test loss is: 0.2634, metrics result is [0.9382804], train loss is 0.2118864804506302\n",
      " 22%|██▏       | 22/100 [05:31<18:59, 14.61s/it]2020-12-17 04:41:45,977 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 22, test loss is: 0.2580, metrics result is [0.93730026], train loss is 0.20536479353904724\n",
      " 23%|██▎       | 23/100 [05:45<18:34, 14.48s/it]2020-12-17 04:42:01,148 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 23, test loss is: 0.2521, metrics result is [0.93885976], train loss is 0.19937442243099213\n",
      " 24%|██▍       | 24/100 [06:00<18:36, 14.69s/it]2020-12-17 04:42:16,013 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 24, test loss is: 0.2482, metrics result is [0.9390615], train loss is 0.1939496248960495\n",
      " 25%|██▌       | 25/100 [06:15<18:25, 14.74s/it]2020-12-17 04:42:30,967 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 25, test loss is: 0.2443, metrics result is [0.9394509], train loss is 0.188959538936615\n",
      " 26%|██▌       | 26/100 [06:30<18:15, 14.80s/it]2020-12-17 04:42:46,389 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 26, test loss is: 0.2384, metrics result is [0.941778], train loss is 0.1838189959526062\n",
      " 27%|██▋       | 27/100 [06:45<18:14, 14.99s/it]2020-12-17 04:42:59,581 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 27, test loss is: 0.2364, metrics result is [0.94223344], train loss is 0.1797095537185669\n",
      " 28%|██▊       | 28/100 [06:59<17:20, 14.45s/it]2020-12-17 04:43:13,728 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 28, test loss is: 0.2314, metrics result is [0.94105184], train loss is 0.17493173480033875\n",
      " 29%|██▉       | 29/100 [07:13<16:59, 14.36s/it]2020-12-17 04:43:28,170 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 29, test loss is: 0.2291, metrics result is [0.9421811], train loss is 0.17129386961460114\n",
      " 30%|███       | 30/100 [07:27<16:46, 14.38s/it]2020-12-17 04:43:42,426 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 30, test loss is: 0.2270, metrics result is [0.941983], train loss is 0.1676708459854126\n",
      " 31%|███       | 31/100 [07:41<16:29, 14.35s/it]2020-12-17 04:43:57,370 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 31, test loss is: 0.2237, metrics result is [0.94247985], train loss is 0.1636212170124054\n",
      " 32%|███▏      | 32/100 [07:56<16:27, 14.53s/it]2020-12-17 04:44:11,485 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 32, test loss is: 0.2203, metrics result is [0.942548], train loss is 0.160307839512825\n",
      " 33%|███▎      | 33/100 [08:10<16:04, 14.40s/it]2020-12-17 04:44:26,137 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 33, test loss is: 0.2185, metrics result is [0.9426717], train loss is 0.15689215064048767\n",
      " 34%|███▍      | 34/100 [08:25<15:55, 14.48s/it]2020-12-17 04:44:41,324 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 34, test loss is: 0.2145, metrics result is [0.9445822], train loss is 0.15374155342578888\n",
      " 35%|███▌      | 35/100 [08:40<15:54, 14.69s/it]2020-12-17 04:44:55,932 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 35, test loss is: 0.2146, metrics result is [0.9430957], train loss is 0.15085694193840027\n",
      " 36%|███▌      | 36/100 [08:55<15:38, 14.67s/it]2020-12-17 04:45:10,986 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 36, test loss is: 0.2121, metrics result is [0.94282967], train loss is 0.14814120531082153\n",
      " 37%|███▋      | 37/100 [09:10<15:31, 14.78s/it]2020-12-17 04:45:25,628 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 37, test loss is: 0.2102, metrics result is [0.942574], train loss is 0.1453234851360321\n",
      " 38%|███▊      | 38/100 [09:25<15:13, 14.74s/it]2020-12-17 04:45:40,039 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 38, test loss is: 0.2080, metrics result is [0.9445846], train loss is 0.14256291091442108\n",
      " 39%|███▉      | 39/100 [09:39<14:53, 14.64s/it]2020-12-17 04:45:53,007 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 39, test loss is: 0.2058, metrics result is [0.94567686], train loss is 0.14011120796203613\n",
      " 40%|████      | 40/100 [09:52<14:08, 14.14s/it]2020-12-17 04:46:05,658 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 40, test loss is: 0.2050, metrics result is [0.9435728], train loss is 0.13747835159301758\n",
      " 41%|████      | 41/100 [10:05<13:27, 13.69s/it]2020-12-17 04:46:19,757 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 41, test loss is: 0.2020, metrics result is [0.9440575], train loss is 0.13524943590164185\n",
      " 42%|████▏     | 42/100 [10:19<13:21, 13.81s/it]2020-12-17 04:46:33,998 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 42, test loss is: 0.2004, metrics result is [0.9447068], train loss is 0.1329827904701233\n",
      " 43%|████▎     | 43/100 [10:33<13:14, 13.94s/it]2020-12-17 04:46:48,513 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 43, test loss is: 0.2017, metrics result is [0.9428434], train loss is 0.13076052069664001\n",
      " 44%|████▍     | 44/100 [10:48<13:10, 14.11s/it]2020-12-17 04:47:03,702 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 44, test loss is: 0.1990, metrics result is [0.94435745], train loss is 0.1285683810710907\n",
      " 45%|████▌     | 45/100 [11:03<13:14, 14.44s/it]2020-12-17 04:47:19,309 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 45, test loss is: 0.1971, metrics result is [0.9443583], train loss is 0.12667745351791382\n",
      " 46%|████▌     | 46/100 [11:18<13:18, 14.79s/it]2020-12-17 04:47:33,786 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 46, test loss is: 0.1967, metrics result is [0.9441518], train loss is 0.12484584748744965\n",
      " 47%|████▋     | 47/100 [11:33<12:58, 14.69s/it]2020-12-17 04:47:48,688 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 47, test loss is: 0.1955, metrics result is [0.94558007], train loss is 0.12267062067985535\n",
      " 48%|████▊     | 48/100 [11:48<12:47, 14.76s/it]2020-12-17 04:48:02,841 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 48, test loss is: 0.1924, metrics result is [0.9468944], train loss is 0.12064795196056366\n",
      " 49%|████▉     | 49/100 [12:02<12:23, 14.58s/it]2020-12-17 04:48:16,794 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 49, test loss is: 0.1929, metrics result is [0.94627553], train loss is 0.11890652775764465\n",
      " 50%|█████     | 50/100 [12:16<11:59, 14.39s/it]2020-12-17 04:48:31,799 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 50, test loss is: 0.1921, metrics result is [0.94587165], train loss is 0.11723757535219193\n",
      " 51%|█████     | 51/100 [12:31<11:54, 14.57s/it]2020-12-17 04:48:47,059 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 51, test loss is: 0.1907, metrics result is [0.9460624], train loss is 0.11545038223266602\n",
      " 52%|█████▏    | 52/100 [12:46<11:49, 14.78s/it]2020-12-17 04:49:01,201 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 52, test loss is: 0.1900, metrics result is [0.9458643], train loss is 0.11369908601045609\n",
      " 53%|█████▎    | 53/100 [13:00<11:25, 14.59s/it]2020-12-17 04:49:16,013 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 53, test loss is: 0.1886, metrics result is [0.9461946], train loss is 0.11202335357666016\n",
      " 54%|█████▍    | 54/100 [13:15<11:14, 14.66s/it]2020-12-17 04:49:30,999 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 54, test loss is: 0.1876, metrics result is [0.9473816], train loss is 0.11042731255292892\n",
      " 55%|█████▌    | 55/100 [13:30<11:03, 14.75s/it]2020-12-17 04:49:45,379 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 55, test loss is: 0.1877, metrics result is [0.9460507], train loss is 0.10897473990917206\n",
      " 56%|█████▌    | 56/100 [13:44<10:44, 14.64s/it]2020-12-17 04:50:00,616 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 56, test loss is: 0.1862, metrics result is [0.94544], train loss is 0.1075059100985527\n",
      " 57%|█████▋    | 57/100 [14:00<10:37, 14.82s/it]2020-12-17 04:50:14,695 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 57, test loss is: 0.1857, metrics result is [0.94674844], train loss is 0.10590206831693649\n",
      " 58%|█████▊    | 58/100 [14:14<10:13, 14.60s/it]2020-12-17 04:50:29,840 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 58, test loss is: 0.1837, metrics result is [0.9470258], train loss is 0.10452142357826233\n",
      " 59%|█████▉    | 59/100 [14:29<10:05, 14.76s/it]2020-12-17 04:50:44,405 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 59, test loss is: 0.1845, metrics result is [0.94696915], train loss is 0.10339982807636261\n",
      " 60%|██████    | 60/100 [14:43<09:48, 14.70s/it]2020-12-17 04:50:59,094 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 60, test loss is: 0.1820, metrics result is [0.94720185], train loss is 0.10185976326465607\n",
      " 61%|██████    | 61/100 [14:58<09:33, 14.70s/it]2020-12-17 04:51:14,191 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 61, test loss is: 0.1816, metrics result is [0.9470326], train loss is 0.10074236989021301\n",
      " 62%|██████▏   | 62/100 [15:13<09:23, 14.82s/it]2020-12-17 04:51:28,077 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 62, test loss is: 0.1809, metrics result is [0.9480569], train loss is 0.09916802495718002\n",
      " 63%|██████▎   | 63/100 [15:27<08:57, 14.54s/it]2020-12-17 04:51:42,336 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 63, test loss is: 0.1800, metrics result is [0.9473428], train loss is 0.0979011133313179\n",
      " 64%|██████▍   | 64/100 [15:41<08:40, 14.45s/it]2020-12-17 04:51:57,462 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 64, test loss is: 0.1791, metrics result is [0.9477555], train loss is 0.09674360603094101\n",
      " 65%|██████▌   | 65/100 [15:56<08:32, 14.66s/it]2020-12-17 04:52:12,694 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 65, test loss is: 0.1785, metrics result is [0.94771576], train loss is 0.09557206183671951\n",
      " 66%|██████▌   | 66/100 [16:12<08:24, 14.83s/it]2020-12-17 04:52:27,318 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 66, test loss is: 0.1793, metrics result is [0.9472746], train loss is 0.09430655837059021\n",
      " 67%|██████▋   | 67/100 [16:26<08:07, 14.77s/it]2020-12-17 04:52:41,592 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 67, test loss is: 0.1773, metrics result is [0.9483607], train loss is 0.09306678175926208\n",
      " 68%|██████▊   | 68/100 [16:41<07:47, 14.62s/it]2020-12-17 04:52:56,078 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 68, test loss is: 0.1774, metrics result is [0.9488727], train loss is 0.09199076890945435\n",
      " 69%|██████▉   | 69/100 [16:55<07:31, 14.58s/it]2020-12-17 04:53:10,654 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 69, test loss is: 0.1761, metrics result is [0.9497316], train loss is 0.09083106368780136\n",
      " 70%|███████   | 70/100 [17:10<07:17, 14.58s/it]2020-12-17 04:53:25,185 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 70, test loss is: 0.1755, metrics result is [0.9484725], train loss is 0.08981751650571823\n",
      " 71%|███████   | 71/100 [17:24<07:02, 14.56s/it]2020-12-17 04:53:39,768 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 71, test loss is: 0.1757, metrics result is [0.9482325], train loss is 0.08878779411315918\n",
      " 72%|███████▏  | 72/100 [17:39<06:47, 14.57s/it]2020-12-17 04:53:54,988 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 72, test loss is: 0.1748, metrics result is [0.94814855], train loss is 0.08781259506940842\n",
      " 73%|███████▎  | 73/100 [17:54<06:38, 14.77s/it]2020-12-17 04:54:09,861 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 73, test loss is: 0.1746, metrics result is [0.947639], train loss is 0.0866893008351326\n",
      " 74%|███████▍  | 74/100 [18:09<06:24, 14.80s/it]2020-12-17 04:54:24,898 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 74, test loss is: 0.1739, metrics result is [0.94816446], train loss is 0.08562343567609787\n",
      " 75%|███████▌  | 75/100 [18:24<06:11, 14.87s/it]2020-12-17 04:54:40,107 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 75, test loss is: 0.1743, metrics result is [0.947839], train loss is 0.08473304659128189\n",
      " 76%|███████▌  | 76/100 [18:39<05:59, 14.97s/it]2020-12-17 04:54:55,423 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 76, test loss is: 0.1725, metrics result is [0.94916666], train loss is 0.08364196866750717\n",
      " 77%|███████▋  | 77/100 [18:54<05:46, 15.07s/it]2020-12-17 04:55:10,212 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 77, test loss is: 0.1727, metrics result is [0.94864905], train loss is 0.08265553414821625\n",
      " 78%|███████▊  | 78/100 [19:09<05:29, 14.99s/it]2020-12-17 04:55:25,237 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 78, test loss is: 0.1717, metrics result is [0.9480408], train loss is 0.08184995502233505\n",
      " 79%|███████▉  | 79/100 [19:24<05:14, 15.00s/it]2020-12-17 04:55:39,680 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 79, test loss is: 0.1717, metrics result is [0.9478434], train loss is 0.08081075549125671\n",
      " 80%|████████  | 80/100 [19:39<04:56, 14.83s/it]2020-12-17 04:55:54,778 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 80, test loss is: 0.1713, metrics result is [0.9485611], train loss is 0.07985586673021317\n",
      " 81%|████████  | 81/100 [19:54<04:43, 14.91s/it]2020-12-17 04:56:09,383 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 81, test loss is: 0.1706, metrics result is [0.9480569], train loss is 0.07907185703516006\n",
      " 82%|████████▏ | 82/100 [20:08<04:26, 14.82s/it]2020-12-17 04:56:24,426 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 82, test loss is: 0.1704, metrics result is [0.949245], train loss is 0.07851829379796982\n",
      " 83%|████████▎ | 83/100 [20:23<04:13, 14.89s/it]2020-12-17 04:56:39,848 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 83, test loss is: 0.1702, metrics result is [0.9487413], train loss is 0.07741890847682953\n",
      " 84%|████████▍ | 84/100 [20:39<04:00, 15.05s/it]2020-12-17 04:56:54,710 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 84, test loss is: 0.1692, metrics result is [0.9487716], train loss is 0.07651591300964355\n",
      " 85%|████████▌ | 85/100 [20:54<03:44, 14.99s/it]2020-12-17 04:57:09,540 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 85, test loss is: 0.1686, metrics result is [0.9496611], train loss is 0.0757264569401741\n",
      " 86%|████████▌ | 86/100 [21:09<03:29, 14.94s/it]2020-12-17 04:57:23,339 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 86, test loss is: 0.1686, metrics result is [0.94898057], train loss is 0.07480894774198532\n",
      " 87%|████████▋ | 87/100 [21:22<03:09, 14.60s/it]2020-12-17 04:57:37,756 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 87, test loss is: 0.1682, metrics result is [0.9502835], train loss is 0.07424814254045486\n",
      " 88%|████████▊ | 88/100 [21:37<02:54, 14.54s/it]2020-12-17 04:57:50,894 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 88, test loss is: 0.1686, metrics result is [0.9493411], train loss is 0.0735098347067833\n",
      " 89%|████████▉ | 89/100 [21:50<02:35, 14.12s/it]2020-12-17 04:58:04,291 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 89, test loss is: 0.1675, metrics result is [0.94995046], train loss is 0.07268814742565155\n",
      " 90%|█████████ | 90/100 [22:03<02:19, 13.91s/it]2020-12-17 04:58:18,950 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 90, test loss is: 0.1670, metrics result is [0.94999033], train loss is 0.07189974933862686\n",
      " 91%|█████████ | 91/100 [22:18<02:07, 14.13s/it]2020-12-17 04:58:34,183 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 91, test loss is: 0.1674, metrics result is [0.9488675], train loss is 0.07119859009981155\n",
      " 92%|█████████▏| 92/100 [22:33<01:55, 14.46s/it]2020-12-17 04:58:48,612 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 92, test loss is: 0.1673, metrics result is [0.9490329], train loss is 0.07042945176362991\n",
      " 93%|█████████▎| 93/100 [22:48<01:41, 14.45s/it]2020-12-17 04:59:02,734 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 93, test loss is: 0.1665, metrics result is [0.9499763], train loss is 0.06970448791980743\n",
      " 94%|█████████▍| 94/100 [23:02<01:26, 14.35s/it]2020-12-17 04:59:17,338 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 94, test loss is: 0.1665, metrics result is [0.94914216], train loss is 0.06899458169937134\n",
      " 95%|█████████▌| 95/100 [23:16<01:12, 14.43s/it]2020-12-17 04:59:32,590 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 95, test loss is: 0.1659, metrics result is [0.9487621], train loss is 0.0682884007692337\n",
      " 96%|█████████▌| 96/100 [23:32<00:58, 14.68s/it]2020-12-17 04:59:47,578 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 96, test loss is: 0.1665, metrics result is [0.9482501], train loss is 0.067659892141819\n",
      " 97%|█████████▋| 97/100 [23:47<00:44, 14.77s/it]2020-12-17 05:00:02,370 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 97, test loss is: 0.1651, metrics result is [0.94896185], train loss is 0.0668674036860466\n",
      " 98%|█████████▊| 98/100 [24:01<00:29, 14.78s/it]2020-12-17 05:00:16,809 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 98, test loss is: 0.1649, metrics result is [0.9493639], train loss is 0.06623871624469757\n",
      " 99%|█████████▉| 99/100 [24:16<00:14, 14.67s/it]2020-12-17 05:00:31,805 - <ipython-input-7-a8ee6df97764>[line:60] - INFO: At round 99, test loss is: 0.1642, metrics result is [0.9490597], train loss is 0.06562339514493942\n",
      "100%|██████████| 100/100 [24:31<00:00, 14.71s/it]\n"
     ]
    }
   ],
   "source": [
    "server.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('dh': conda)",
   "language": "python",
   "name": "python37364bitdhcondadf59eeb9b0ab4d0f8e99f22a0eb1c034"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}